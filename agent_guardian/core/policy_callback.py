"""
Enhanced Policy Enforcement Callback for LiteLLM
Refactored version using modular components
"""

import logging
import re
import threading
import json
import ast
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path

from litellm.integrations.custom_logger import CustomLogger
import yaml

from ..config import EnforcementConfig
from ..storage import SQLiteLogger, PolicyAuditLogger
from ..utils import PathResolver
from .workflow_validator import validate_workflow
from .semantic_validator import get_semantic_validator

logger = logging.getLogger(__name__)

# Logging configuration from environment
import os
LOG_LEVEL = os.environ.get('POLICY_LOG_LEVEL', 'INFO').upper()
ENABLE_DEBUG_PRINTS = LOG_LEVEL == 'DEBUG'
ENABLE_INFO_PRINTS = LOG_LEVEL in ['DEBUG', 'INFO']

def debug_print(message: str, force: bool = False):
    """Print debug messages only if debug logging is enabled."""
    if ENABLE_DEBUG_PRINTS or force:
        print(f"[DEBUG] {message}", flush=True)

def info_print(message: str, force: bool = False):
    """Print info messages only if info logging is enabled."""
    if ENABLE_INFO_PRINTS or force:
        print(f"[INFO] {message}", flush=True)

def warning_print(message: str):
    """Always print warnings."""
    print(f"[WARNING] {message}", flush=True)

def error_print(message: str):
    """Always print errors."""
    print(f"[ERROR] {message}", flush=True)


# Agent role mapping - can be extended by users
AGENT_ROLE_MAPPINGS = {
    # Enhanced Knowledge Assistant Agents
    "Senior Data Analyst": "Senior_Data_Analyst",
    "Senior Data Researcher": "Senior_Data_Researcher",
    "Research Agent": "Senior_Data_Researcher",
    "Research Data Archivist and File System Manager": "Research_Data_Archivist_and_File_System_Manager",
    "Research Communications Specialist": "Research_Communications_Specialist",
    
    # Trip Planner Agents
    "City Selection Expert": "City_Selection_Expert",
    "Local Expert and Travel Guide": "Local_Expert_and_Travel_Guide",
    "Amazing Travel Concierge": "Amazing_Travel_Concierge",

    # IT Support Agents
    "IT Support Diagnostic Specialist": "IT_Support_Diagnostic_Specialist",
    "IT Alert and Ticketing Coordinator": "IT_Alert_and_Ticketing_Coordinator",

    # AgentDojo Slack
    "AI Assistant": "AI_Assistant"
}

# Policy folder names - can be extended by users
POLICY_FOLDERS = [
    "policies_knowledge_enhanced",
    "policies_knowledge_basic",
    "policies_trip_planner", 
    "policies_it_assistant",
    "policies_slack"
]


class SimplePolicyCallback(CustomLogger):
    """
    Enhanced policy enforcement callback that works across multiple applications.
    Refactored to use modular components and configuration.
    """
    
    def __init__(
        self, 
        config: EnforcementConfig,
        agent_role_mappings: Optional[Dict[str, str]] = None,
        policy_folders: Optional[List[str]] = None
    ):
        """
        Initialize policy callback with configuration.
        
        Args:
            config: EnforcementConfig instance
            agent_role_mappings: Optional custom agent role mappings (extends defaults)
            policy_folders: Optional custom policy folder names (extends defaults)
        """
        super().__init__()
        
        self.config = config
        
        # Merge custom mappings with defaults
        self.agent_role_mappings = AGENT_ROLE_MAPPINGS.copy()
        if agent_role_mappings:
            self.agent_role_mappings.update(agent_role_mappings)
        
        # Merge custom policy folders with defaults
        self.policy_folders = POLICY_FOLDERS.copy()
        if policy_folders:
            self.policy_folders.extend(policy_folders)
        
        # Generate unique instance ID
        self.instance_id = f"callback_{id(self)}"
        
        # In-memory session history cache
        self.session_history: Dict[str, List[str]] = {}
        self.session_history_lock = threading.Lock()
        
        # Initialize storage loggers
        self.sqlite_logger = None
        self.audit_logger = None
        
        if config.enable_audit_logging:
            try:
                self.sqlite_logger = SQLiteLogger(config.db_path)
                self.audit_logger = PolicyAuditLogger(config.db_path)
                info_print(f"SQLite logging enabled for {self.instance_id}")
            except Exception as e:
                warning_print(f"SQLite logging disabled due to error: {e}")
                config.enable_audit_logging = False
        
        # Initialize semantic validator
        self.semantic_validator = None
        if config.enable_semantic_validation:
            try:
                self.semantic_validator = get_semantic_validator(
                    ollama_host=config.ollama_host,
                    model=config.semantic_model
                )
                info_print(f"Semantic validation enabled for {self.instance_id}")
            except Exception as e:
                warning_print(f"Semantic validation disabled due to error: {e}")
                config.enable_semantic_validation = False
        
        info_print(f"Policy callback initialized: {self.instance_id}")

    def _extract_agent_role(self, messages: List[Dict[str, Any]]) -> Optional[str]:
        """Extract agent role from system message and normalize using mappings."""
        full_extracted_role = None
        for message in messages:
            content = message.get('content', '')
            if message.get('role') == 'system' and isinstance(content, str):
                # Pattern 1: "You are a/an [role]"
                match = re.search(r"You are (?:a |an )?(.+?)(?:\.|$|\n)", content, re.IGNORECASE)
                if match:
                    full_extracted_role = match.group(1).strip().split('.')[0].split('\n')[0]
                    break
                
                # Pattern 2: "You're a/an [role]"
                match = re.search(r"You're (?:a |an )?(.+?)(?:\.|$|\n)", content, re.IGNORECASE)
                if match:
                    full_extracted_role = match.group(1).strip().split('.')[0].split('\n')[0]
                    break
        
        if full_extracted_role:
            # Check if there's a mapping for this role
            for role_key, folder_name in self.agent_role_mappings.items():
                if role_key in full_extracted_role:
                    debug_print(f"Mapped role '{full_extracted_role}' -> '{folder_name}'")
                    return folder_name
            
            # If no mapping found, return as-is (for extensibility)
            debug_print(f"No mapping found for role '{full_extracted_role}', using as-is")
            return full_extracted_role
        
        return None

    def _load_specific_policy(self, agent_role_for_folder: str, action_name: str) -> Optional[Dict[str, Any]]:
        """Load the specific policy.yaml for a given agent role and action name."""
        
        print(f"\n{'='*80}")
        print(f"ðŸ” POLICY SEARCH DEBUG")
        print(f"{'='*80}")
        print(f"Agent Role: {agent_role_for_folder}")
        print(f"Action Name: {action_name}")
        print(f"Policy Base Dir: {self.config.policy_dir}")
        print(f"Policy Folders to Search: {self.policy_folders}")
        print(f"{'='*80}\n")
        
        # Try to find the policy file
        policy_file = PathResolver.find_policy_file(
            policy_dir=self.config.policy_dir,
            agent_role=agent_role_for_folder,
            action_name=action_name,
            policy_folders=self.policy_folders
        )
        
        if policy_file:
            print(f"âœ… FOUND POLICY FILE: {policy_file}\n")
            try:
                with open(policy_file, 'r') as f:
                    policy_data = yaml.safe_load(f)
                    print(f"âœ… Successfully loaded policy from: {policy_file}\n")
                    return policy_data
            except Exception as e:
                print(f"âŒ ERROR loading policy file: {e}\n")
                error_print(f"Failed to load policy from {policy_file}: {e}")
                return None
        else:
            print(f"âŒ NO POLICY FILE FOUND")
            print(f"   Searched in:")
            for folder in self.policy_folders:
                search_path = self.config.policy_dir / folder / agent_role_for_folder
                print(f"   - {search_path}")
            print(f"\n")
            return None

    def _extract_function_arguments(self, response_obj: Any, action_name: str = None) -> Dict[str, Any]:
        """Extract function arguments from LLM response with robust parsing."""
        try:
            if not hasattr(response_obj, 'choices') or not response_obj.choices:
                return {}
            
            message = response_obj.choices[0].message
            
            # Priority 1: Modern Tool Calls
            if hasattr(message, 'tool_calls') and message.tool_calls:
                for tool_call in message.tool_calls:
                    if hasattr(tool_call, 'function') and hasattr(tool_call.function, 'arguments'):
                        args_str = tool_call.function.arguments
                        
                        if isinstance(args_str, str):
                            try:
                                return json.loads(args_str, strict=False)
                            except json.JSONDecodeError:
                                try:
                                    return ast.literal_eval(args_str)
                                except:
                                    return {}
                        elif isinstance(args_str, dict):
                            return args_str

            # Priority 2: Legacy/String Content Parsing
            content = getattr(message, 'content', '') or ''
            if content:
                match = re.search(r'##\s*Tool Input:\s*\n\s*"?(\{.+?\})"?', content, re.IGNORECASE | re.DOTALL)
                if not match:
                    match = re.search(r"Action Input:\s*(.+?)(?:\n\n|$)", content, re.IGNORECASE | re.DOTALL)
                
                if match:
                    args_str = match.group(1).strip()
                    
                    # Remove wrapping quotes only
                    if args_str.startswith('"') and args_str.endswith('"'):
                        args_str = args_str[1:-1]
                    
                    # Extract JSON
                    start_idx = args_str.find('{')
                    if start_idx == -1:
                        return {}

                    brace_level = 0
                    end_idx = -1
                    
                    for i, char in enumerate(args_str[start_idx:]):
                        if char == '{':
                            brace_level += 1
                        elif char == '}':
                            brace_level -= 1
                        
                        if brace_level == 0:
                            end_idx = start_idx + i + 1
                            break
                    
                    if end_idx == -1:
                        return {}

                    clean_json_str = args_str[start_idx:end_idx]
                    
                    # Try JSON first, then Python literal eval
                    try:
                        return json.loads(clean_json_str, strict=False)
                    except json.JSONDecodeError:
                        pass

                    try:
                        debug_print(f"JSON parse failed, attempting Python AST eval...")
                        return ast.literal_eval(clean_json_str)
                    except Exception:
                        pass
            
            return {}
        
        except Exception as e:
            warning_print(f"Could not extract function arguments: {e}")
            return {}

    def _extract_action_from_response_obj(self, response_obj: Any) -> tuple[Optional[str], str]:
        """Extract the action name from LiteLLM's response_obj."""
        try:
            if not hasattr(response_obj, 'choices') or not response_obj.choices:
                return None, "no_choices"
            
            message = response_obj.choices[0].message

            if hasattr(message, 'tool_calls') and message.tool_calls:
                for tool_call in message.tool_calls:
                    if hasattr(tool_call, 'function') and hasattr(tool_call.function, 'name'):
                        return tool_call.function.name, "tool_calls"
            
            content = getattr(message, 'content', None)
            if content:
                match = re.search(r"Action:\s*(.+?)(?:\n|$)", content, re.IGNORECASE)
                if match:
                    return match.group(1).strip(), "content_regex"
            
            return None, "no_action_found"
        except Exception as e:
            error_print(f"Exception in _extract_action_from_response_obj: {e}")
            return None, f"exception_{str(e)[:50]}"

    def _check_violations(
        self, 
        session_id: str,
        input_tokens: int,
        output_tokens: int,
        token_limits: Dict[str, int],
        time_limits: Dict[str, str],
        actual_duration_ms: int,
        duration_limits: Dict[str, int],
        function_args: Dict[str, Any],
        pattern_limits: Dict[str, Any],
        agent_role: str,
        action_name: str
    ) -> List[str]:
        """Check for all policy violations and return list of violation messages."""
        violations = []
        failed_structured_fields = set()
        
        # TOKEN LIMIT CHECKS
        if token_limits:
            min_in = token_limits.get('min_input_tokens')
            max_in = token_limits.get('max_input_tokens')
            min_out = token_limits.get('min_output_tokens')
            max_out = token_limits.get('max_output_tokens')
            
            if min_in and input_tokens < min_in:
                violations.append(f"Input tokens ({input_tokens}) below minimum ({min_in})")
            if max_in and input_tokens > max_in:
                violations.append(f"Input tokens ({input_tokens}) exceeds maximum ({max_in})")
            if min_out and output_tokens < min_out:
                violations.append(f"Output tokens ({output_tokens}) below minimum ({min_out})")
            if max_out and output_tokens > max_out:
                violations.append(f"Output tokens ({output_tokens}) exceeds maximum ({max_out})")
        
        # TIME WINDOW CHECKS
        if time_limits:
            current_time_str = datetime.now().strftime('%H:%M:%S')
            min_time_str = time_limits.get('min_hour')
            max_time_str = time_limits.get('max_hour')
            
            if min_time_str and max_time_str:
                try:
                    current_time = datetime.strptime(current_time_str, '%H:%M:%S').time()
                    min_time = datetime.strptime(min_time_str, '%H:%M:%S').time()
                    max_time = datetime.strptime(max_time_str, '%H:%M:%S').time()
                    
                    if not (min_time <= current_time <= max_time):
                        violations.append(
                            f"Execution time ({current_time_str}) is outside allowed window "
                            f"({min_time_str} - {max_time_str})"
                        )
                except Exception as e:
                    debug_print(f"Time check error: {e}")
        
        # DURATION CHECKS
        if duration_limits:
            min_duration = duration_limits.get('min_processing_duration')
            max_duration = duration_limits.get('max_processing_duration')
            
            if min_duration and actual_duration_ms < min_duration:
                violations.append(f"Processing duration ({actual_duration_ms}ms) below minimum ({min_duration}ms)")
            if max_duration and actual_duration_ms > max_duration:
                violations.append(f"Processing duration ({actual_duration_ms}ms) exceeds maximum ({max_duration}ms)")
        
        # FORBIDDEN PATTERN CHECKS
        forbidden_patterns = pattern_limits.get("forbidden_patterns", [])
        if forbidden_patterns:
            for param_name, forbidden_pattern_list in forbidden_patterns.items():
                if param_name in function_args:
                    actual_value = function_args[param_name]
                    if isinstance(actual_value, bool):
                        actual_value = str(actual_value).lower()
                    else:
                        actual_value = str(actual_value)
                    
                    for forbidden_regex in forbidden_pattern_list:
                        try:
                            if re.match(forbidden_regex, actual_value):
                                violations.append(
                                    f"Forbidden pattern violation: '{param_name}' value '{actual_value}' "
                                    f"matches forbidden pattern '{forbidden_regex}'"
                                )
                                failed_structured_fields.add(param_name)
                                break
                        except Exception as e:
                            debug_print(f"Forbidden pattern check error: {e}")
        
        # ALLOWED INPUT PATTERN CHECKS
        input_patterns = pattern_limits.get("input_patterns", [])
        if input_patterns and not any('Forbidden pattern violation' in v for v in violations):
            any_complete_pattern_matched = False
            
            for allowed_pattern_dict in input_patterns:
                this_pattern_matches = True
                
                for param_name, pattern_config in allowed_pattern_dict.items():
                    if param_name not in function_args:
                        this_pattern_matches = False
                        break

                    actual_value = str(function_args[param_name])
                    param_matched = False

                    pattern_list_to_check = pattern_config if isinstance(pattern_config, list) else [str(pattern_config)]

                    for allowed_regex in pattern_list_to_check:
                        try:
                            if re.match(allowed_regex, actual_value):
                                param_matched = True
                                debug_print(f"Pattern matched: {param_name}={actual_value} matches {allowed_regex}")
                                break
                        except Exception as e:
                            debug_print(f"Pattern matching error for {param_name}: {e}")

                    if not param_matched:
                        debug_print(f"Pattern NOT matched: {param_name}={actual_value} against {pattern_list_to_check}")
                        this_pattern_matches = False
                        failed_structured_fields.add(param_name)
                        break
                
                if this_pattern_matches:
                    any_complete_pattern_matched = True
                    debug_print(f"Complete pattern matched!")
                    break
            
            if not any_complete_pattern_matched:
                violations.append(
                    f"Input pattern violation: Function arguments {function_args} "
                    f"did not match any of the allowed patterns."
                )
        
        # SEMANTIC VALIDATION
        if self.config.enable_semantic_validation and self.semantic_validator:
            semantic_checks = pattern_limits.get("semantic_descriptions", {})
            
            if semantic_checks:
                for field_name, semantic_description in semantic_checks.items():
                    if field_name not in function_args:
                        debug_print(f"Skipping semantic validation for {field_name} (field not in function_args)")
                        continue
                    
                    if field_name in failed_structured_fields:
                        debug_print(f"Skipping semantic validation for {field_name} (already failed structured check)")
                        continue
                    
                    field_value = function_args[field_name]
                    debug_print(f"Running semantic validation for field: {field_name}")
                    
                    try:
                        result = self.semantic_validator.validate_field(
                            field_name=field_name,
                            field_value=field_value,
                            semantic_description=semantic_description
                        )
                        
                        if "_semantic_checks" not in function_args:
                            function_args["_semantic_checks"] = {}
                        
                        function_args["_semantic_checks"][field_name] = {
                            "description": semantic_description,
                            "qwen_verdict": "VIOLATION" if result['is_violation'] else "PASS",
                            "qwen_reasoning": result['reasoning'],
                            "duration_ms": result['duration_ms']
                        }
                        
                        if result['is_violation']:
                            violations.append(f"Semantic violation ({field_name}): {result['reasoning']}")
                            warning_print(f"âš ï¸ Semantic violation detected for {field_name}")
                        else:
                            info_print(f"âœ… Semantic validation passed for {field_name}")
                    except Exception as e:
                        error_print(f"Error during semantic validation: {e}")
                        violations.append(f"Semantic validation system error: {e}")
        
        # WORKFLOW VALIDATION
        if self.config.enable_workflow_validation:
            try:
                execution_history = []
                
                with self.session_history_lock:
                    execution_history = self.session_history.get(session_id, []).copy()
                
                if not execution_history and self.sqlite_logger:
                    debug_print(f"In-memory history for {session_id} is empty, falling back to DB.")
                    execution_history = self.sqlite_logger.get_execution_history(session_id)
                else:
                    debug_print(f"Got execution history from in-memory cache for {session_id}: {execution_history}")
                
                graph_filename = f"{agent_role.replace(' ', '_')}_graph.yaml"
                graph_path = None

                for policy_folder in self.policy_folders:
                    test_path = self.config.policy_dir / policy_folder / agent_role / graph_filename
                    if test_path.exists():
                        graph_path = test_path
                        debug_print(f"Found workflow graph for {agent_role} at: {graph_path}")
                        break

                if graph_path:
                    debug_print(f"Checking workflow for {agent_role} - History: {execution_history}, Next: {action_name}")
                    
                    is_valid, error_msg = validate_workflow(
                        agent_role=agent_role,
                        action_to_execute=action_name,
                        execution_history=execution_history,
                        graph_yaml_path=graph_path
                    )
                    
                    if not is_valid:
                        violations.append(f"Workflow sequence violation: {error_msg}")
                        warning_print(f"âš ï¸ Workflow Graph FAILED for {agent_role} -> {action_name}")
                    else:
                        info_print(f"âœ… Workflow Graph PASSED for {agent_role} -> {action_name}")
                else:
                    info_print(f"No control flow graph found for {agent_role}, skipping workflow validation")
                    
            except Exception as e:
                error_print(f"Error during workflow validation: {e}")
                violations.append(f"Workflow validation system error: {e}")
                
        return violations

    def _extract_token_limits(self, policy_data: Dict[str, Any]) -> Dict[str, int]:
        """Extract token limits from policy data."""
        token_limits = {}
        try:
            numeric_limits = policy_data.get('input_restrictions', {}).get('numeric_limits', {})
            
            if 'input_tokens' in numeric_limits:
                input_tokens = numeric_limits['input_tokens']
                token_limits['min_input_tokens'] = input_tokens.get('min_input_tokens')
                token_limits['max_input_tokens'] = input_tokens.get('max_input_tokens')
                
            if 'output_tokens' in numeric_limits:
                output_tokens = numeric_limits['output_tokens']
                token_limits['max_output_tokens'] = output_tokens.get('max_output_tokens')
                
        except Exception as e:
            debug_print(f"Could not extract token limits from policy: {e}")
        
        return token_limits
    
    def _extract_time_limits(self, policy_data: Dict[str, Any]) -> Dict[str, str]:
        """Extract time restrictions from policy data."""
        time_limits = {}
        try:
            numeric_limits = policy_data.get('input_restrictions', {}).get('numeric_limits', {})
            
            if 'time' in numeric_limits:
                time_restrictions = numeric_limits['time']
                time_limits['min_hour'] = time_restrictions.get('min_hour')
                time_limits['max_hour'] = time_restrictions.get('max_hour')
                
        except Exception as e:
            debug_print(f"Could not extract time limits from policy: {e}")
        
        return time_limits
    
    def _extract_duration_limits(self, policy_data: Dict[str, Any]) -> Dict[str, int]:
        """Extract duration restrictions from policy data."""
        duration_limits = {}
        try:
            numeric_limits = policy_data.get('input_restrictions', {}).get('numeric_limits', {})
            
            if 'duration' in numeric_limits:
                duration_restrictions = numeric_limits['duration']
                duration_limits['min_processing_duration'] = duration_restrictions.get('min_processing_duration')
                duration_limits['max_processing_duration'] = duration_restrictions.get('max_processing_duration')
                
        except Exception as e:
            debug_print(f"Could not extract duration limits from policy: {e}")
        
        return duration_limits

    def _extract_pattern_limits(self, policy_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract pattern restrictions from policy data."""
        pattern_limits = {"input_patterns": [], "forbidden_patterns": [], "semantic_descriptions": {}}
        
        try:
            input_restrictions = policy_data.get('input_restrictions', {})
            categorical_values = input_restrictions.get('categorical_values', [])
            if isinstance(categorical_values, dict): 
                categorical_values = [categorical_values]
            
            for item in categorical_values:
                if isinstance(item, dict):
                    for key, value in item.items():
                        if "input_pattern" in key:
                            pattern_limits["input_patterns"].append(value)
                            
            forbidden_patterns_list = input_restrictions.get('forbidden_patterns', [])
            if isinstance(forbidden_patterns_list, dict): 
                forbidden_patterns_list = [forbidden_patterns_list]
                
            for pattern_item in forbidden_patterns_list:
                if isinstance(pattern_item, dict) and 'pattern' in pattern_item:
                    pattern_limits["forbidden_patterns"].append(pattern_item['pattern'])
            
            semantic_descriptions = input_restrictions.get('semantic_descriptions', {})
            if isinstance(semantic_descriptions, dict):
                pattern_limits["semantic_descriptions"] = semantic_descriptions
                debug_print(f"Extracted semantic descriptions: {list(semantic_descriptions.keys())}")
                            
        except Exception as e:
            debug_print(f"Could not extract pattern limits from policy: {e}")
        
        return pattern_limits

    def _count_tokens(self, messages: List[Dict[str, Any]]) -> int:
        """Simple token counting - approximate by counting words * 1.3."""
        total_text = ""
        for message in messages:
            content = message.get('content', '')
            if isinstance(content, str):
                total_text += content + " "
        
        word_count = len(total_text.split())
        estimated_tokens = int(word_count * 1.3)
        return estimated_tokens
    
    def _count_output_tokens(self, response_obj: Any) -> int:
        """Count tokens in the LLM response."""
        try:
            if not hasattr(response_obj, 'choices') or not response_obj.choices:
                return 0
            
            message = response_obj.choices[0].message
            content = getattr(message, 'content', '') or ''
            
            word_count = len(content.split())
            estimated_tokens = int(word_count * 1.3)
            return estimated_tokens
            
        except Exception as e:
            debug_print(f"Could not count output tokens: {e}")
            return 0

    def _generate_session_id(self, agent_role: str) -> str:
        """Generate persistent session ID for entire crew execution."""
        if not hasattr(self, '_persistent_session_id'):
            start_time = datetime.now().strftime('%Y%m%d_%H%M%S')
            self._persistent_session_id = f"session_{start_time}_{self.instance_id}"
        
        return self._persistent_session_id

    def log_success_event(self, kwargs: Dict[str, Any], response_obj: Any, start_time: float, end_time: float):
        """Log successful requests with policy enforcement and audit."""
        if not ENABLE_INFO_PRINTS:
            return
            
        info_print(f"Processing sync success event for {self.instance_id}")
        
        messages = kwargs.get('messages', [])
        agent_role = self._extract_agent_role(messages)
        action_name, extraction_method = self._extract_action_from_response_obj(response_obj)
        
        session_id = self._generate_session_id(agent_role)
        
        if not agent_role:
            debug_print(f"Could not extract agent_role, skipping policy check")
            return

        if not action_name:
            debug_print(f"No tool found for {agent_role}, skipping policy check (thought step)")
            return
        
        debug_print(f"Policy check for action: {action_name}")
        
        policy_data = self._load_specific_policy(agent_role, action_name)
        
        if policy_data:
            try:
                # Calculate duration
                if isinstance(start_time, (int, float)) and isinstance(end_time, (int, float)):
                    duration_seconds = end_time - start_time
                else:
                    try:
                        duration_seconds = float(end_time) - float(start_time)
                    except (TypeError, ValueError):
                        duration_seconds = (end_time - start_time).total_seconds()
                
                duration_ms = int(duration_seconds * 1000)
                
                input_tokens = self._count_tokens(messages)
                output_tokens = self._count_output_tokens(response_obj)
                function_args = self._extract_function_arguments(response_obj, action_name)
                
                token_limits = self._extract_token_limits(policy_data)
                time_limits = self._extract_time_limits(policy_data)
                duration_limits = self._extract_duration_limits(policy_data)
                pattern_limits = self._extract_pattern_limits(policy_data)
                
                violations = self._check_violations(
                    session_id, input_tokens, output_tokens, token_limits, 
                    time_limits, duration_ms, duration_limits,
                    function_args, pattern_limits,
                    agent_role, action_name
                )
                
                # Prepare audit data
                violation_text = " | ".join(violations) if violations else ""
                
                audit_data = {
                    'timestamp': datetime.now().isoformat()[:19],
                    'agent_role': agent_role,
                    'action_name': action_name,
                    'input_tokens': input_tokens,
                    'output_tokens': output_tokens,
                    'processing_duration_ms': duration_ms,
                    'execution_time': datetime.now().strftime('%H:%M:%S'),
                    'function_args': function_args,
                    'policy_passed': len(violations) == 0,
                    'violation_reasons': violation_text,
                    'session_id': session_id,
                    'callback_instance_id': self.instance_id
                }
                
                # Log to audit database
                if self.audit_logger:
                    self.audit_logger.log_policy_audit(audit_data)
                
                if violations:
                    print(f"\nðŸš¨ POLICY VIOLATIONS DETECTED:", flush=True)
                    for violation in violations:
                        print(f"   âŒ {violation}", flush=True)
                else:
                    info_print("âœ… NO VIOLATIONS DETECTED", force=True)
                
            except Exception as e:
                error_print(f"Error in violation checking: {e}")
        
        # Log to SQLite
        if self.sqlite_logger and policy_data:
            self.sqlite_logger.log_activity(session_id, agent_role, action_name, function_args, [])
            
            # Append to in-memory history cache
            with self.session_history_lock:
                if session_id not in self.session_history:
                    self.session_history[session_id] = []
                self.session_history[session_id].append(action_name)
                debug_print(f"Appended to in-memory history for {session_id}: {action_name}")

    def get_stats(self) -> Dict[str, Any]:
        """Get statistics about policy enforcement."""
        stats = {
            "callback_instance_id": self.instance_id,
            "logging_enabled": self.config.enable_audit_logging,
            "semantic_validation_enabled": self.config.enable_semantic_validation,
            "workflow_validation_enabled": self.config.enable_workflow_validation
        }
        
        if self.sqlite_logger:
            try:
                sqlite_stats = self.sqlite_logger.get_activity_stats()
                stats["sqlite_stats"] = sqlite_stats
            except Exception as e:
                stats["sqlite_error"] = str(e)
        
        return stats

    def reset_session_id(self):
        """Clear the persistent session ID from the callback instance."""
        if hasattr(self, '_persistent_session_id'):
            try:
                with self.session_history_lock:
                    if self._persistent_session_id in self.session_history:
                        del self.session_history[self._persistent_session_id]
                        debug_print(f"Cleared in-memory history for old session {self._persistent_session_id}")
                
                del self._persistent_session_id
                info_print(f"Callback {self.instance_id}: Persistent session ID has been reset.")
            except Exception as e:
                error_print(f"Callback {self.instance_id}: Error resetting session ID: {e}")
        else:
            info_print(f"Callback {self.instance_id}: No session ID to reset. Ready for new crew.")
            
            with self.session_history_lock:
                self.session_history = {}
                debug_print("Cleared all in-memory history as a fallback.")

    def clear_execution_history(self):
        """Clear execution history for the current session without resetting session ID."""
        if hasattr(self, '_persistent_session_id'):
            session_id = self._persistent_session_id
            
            with self.session_history_lock:
                if session_id in self.session_history:
                    action_count = len(self.session_history[session_id])
                    self.session_history[session_id] = []
                    info_print(f"Cleared {action_count} actions from execution history (session: {session_id})")
                else:
                    self.session_history[session_id] = []
                    info_print(f"Initialized empty execution history (session: {session_id})")
        else:
            with self.session_history_lock:
                self.session_history = {}
            info_print("No active session - cleared all execution history")